{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Classifying Vaccine Misinformation using RNN.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "houjBmU6XhHO"
      },
      "source": [
        "# Classifying Vaccine Misinformation using RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moe3P0qoZ5UV",
        "outputId": "71cbadc4-f0f1-4fd1-9731-34370808dc05"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g3OmVKFZ8-a",
        "outputId": "b7cdf2a8-2e5a-4717-9558-47366b9e9aea"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Social Media Analytics')\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/Social Media Analytics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_0GT6y3aBpF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGE-cvjXhHU"
      },
      "source": [
        "# Read in data and split into training and test set\n",
        "# NOTE: we are NOT cleaning the data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "\n",
        "messages = pd.read_csv('information1.csv', encoding='latin-1')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHARyEd4wvnc"
      },
      "source": [
        "text = messages['text']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJSo7s4syo98"
      },
      "source": [
        "# Preprocessing Text data by removing punctuation, stopwords,stemming and tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFjBYH6zwgcH",
        "outputId": "f14d4774-3f6a-4341-895b-6dacaf5bb346"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "\n",
        "# We need this dataset in order to use the tokenizer\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Also download the list of stopwords to filter out\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "sws = set(stopwords.words('english'))\n",
        "sws.add('rt') # Tweet specific stop-words\n",
        "sws.add(\"…\")\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def process_text(text):\n",
        "    # Make all the strings lowercase and remove non alphabetic characters (punctuations)\n",
        "    text = re.sub('[^A-Za-z]', ' ', text.lower())\n",
        "    \n",
        "    # Tokenize the text; this is, separate every sentence into a list of words\n",
        "    # Since the text is already split into sentences you don't have to call sent_tokenize\n",
        "    tokenized_text = word_tokenize(text)\n",
        "    \n",
        "    #tokenized_text = [word_tokenize(text) for word in text if word not in exclude]\n",
        "                    \n",
        "    \n",
        "    # Remove the stopwords and stem each word to its root\n",
        "    clean_text = [\n",
        "        stemmer.stem(word) for word in tokenized_text\n",
        "        if word not in sws\n",
        "    ]\n",
        "\n",
        "    # Remember, this final output is a list of words\n",
        "    return clean_text"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHiqbLHowz1R"
      },
      "source": [
        "clean_text = [process_text(text) for text in text]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vL57IpIxZl9",
        "outputId": "97cd734a-b4ea-48c8-d1b5-db0b1c76f8df"
      },
      "source": [
        "clean_text[2]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nobodi',\n",
              " 'talk',\n",
              " 'efficaci',\n",
              " 'covidvaccin',\n",
              " 'emerg',\n",
              " 'covid',\n",
              " 'variant',\n",
              " 'sure',\n",
              " 'inocul',\n",
              " 'vaccin',\n",
              " 'littl',\n",
              " 'protect',\n",
              " 'variant',\n",
              " 'use',\n",
              " 'efficaci',\n",
              " 'amp',\n",
              " 'updat',\n",
              " 'vaccin',\n",
              " 'due',\n",
              " 'releas',\n",
              " 'normanswan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCCAdBBnvfHA"
      },
      "source": [
        "messages['clean_text'] = clean_text"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "2qGGjTBTu2cK",
        "outputId": "465e22be-f7e6-4dd3-8772-08ccdeac6b8d"
      },
      "source": [
        "messages.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @pranavmahajan: This is important regarding #CovidVaccines. Pls read &amp;amp; share.\\n\\nCredit: @IndiaToday https://t.co/UNkzZRDmfl</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[pranavmahajan, import, regard, covidvaccin, pl, read, amp, share, credit, indiatoday, http, co, unkzzrdmfl]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#CovidVaccines between #GenZ and #Millennials are the next #Challenge for ðºð¸ and ð¬ð§. ðââï¸\\nhttps://t.co/eHG5jKIrWS</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[covidvaccin, genz, millenni, next, challeng, http, co, ehg, jkirw]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why is nobody talking about efficacy of #COVIDVaccines against emerging #COVID19 variants? Surely if we're being inoculated with a vaccine that has little protection against variants then why not use the most efficacious &amp;amp; when are updated vaccines due to be released? @normanswan</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[nobodi, talk, efficaci, covidvaccin, emerg, covid, variant, sure, inocul, vaccin, littl, protect, variant, use, efficaci, amp, updat, vaccin, due, releas, normanswan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@EvanLSolomon @fordnation All because #TrudeauFailedCanada  and did not purchase #COVIDVaccines  soon enough. we should of been giving the second shot by now but here we are scratching, borrowing and pleading with other countries to try to get enough vaccine just for people's first jab. #trudeauð©</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[evanlsolomon, fordnat, trudeaufailedcanada, purchas, covidvaccin, soon, enough, give, second, shot, scratch, borrow, plead, countri, tri, get, enough, vaccin, peopl, first, jab, trudeau]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who are you getting vaccinated for? #GetVaccinated #getthevax #COVIDVaccines https://t.co/xZNjMhi27M</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[get, vaccin, getvaccin, getthevax, covidvaccin, http, co, xznjmhi]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                           text  ...                                                                                                                                                                                   clean_text\n",
              "0                                                                                                                                                                           RT @pranavmahajan: This is important regarding #CovidVaccines. Pls read &amp; share.\\n\\nCredit: @IndiaToday https://t.co/UNkzZRDmfl  ...                                                                                 [pranavmahajan, import, regard, covidvaccin, pl, read, amp, share, credit, indiatoday, http, co, unkzzrdmfl]\n",
              "1                                                                                                                                                                       #CovidVaccines between #GenZ and #Millennials are the next #Challenge for ðºð¸ and ð¬ð§. ðââï¸\\nhttps://t.co/eHG5jKIrWS  ...                                                                                                                          [covidvaccin, genz, millenni, next, challeng, http, co, ehg, jkirw]\n",
              "2                  Why is nobody talking about efficacy of #COVIDVaccines against emerging #COVID19 variants? Surely if we're being inoculated with a vaccine that has little protection against variants then why not use the most efficacious &amp; when are updated vaccines due to be released? @normanswan  ...                      [nobodi, talk, efficaci, covidvaccin, emerg, covid, variant, sure, inocul, vaccin, littl, protect, variant, use, efficaci, amp, updat, vaccin, due, releas, normanswan]\n",
              "3  @EvanLSolomon @fordnation All because #TrudeauFailedCanada  and did not purchase #COVIDVaccines  soon enough. we should of been giving the second shot by now but here we are scratching, borrowing and pleading with other countries to try to get enough vaccine just for people's first jab. #trudeauð©  ...  [evanlsolomon, fordnat, trudeaufailedcanada, purchas, covidvaccin, soon, enough, give, second, shot, scratch, borrow, plead, countri, tri, get, enough, vaccin, peopl, first, jab, trudeau]\n",
              "4                                                                                                                                                                                                          Who are you getting vaccinated for? #GetVaccinated #getthevax #COVIDVaccines https://t.co/xZNjMhi27M  ...                                                                                                                          [get, vaccin, getvaccin, getthevax, covidvaccin, http, co, xznjmhi]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XpN05dGxz0A"
      },
      "source": [
        "X = messages['clean_text'][0:300]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVIUsx_XhHV"
      },
      "source": [
        "y = messages['labels'][0:300]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdrr6gmuXhHW"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rq2-Z2xXhHX"
      },
      "source": [
        "### Prep Data For Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGn04PLuXhHX",
        "outputId": "9233ea24-3d9f-426b-b1ed-0cef039dcde3"
      },
      "source": [
        "# Install keras\n",
        "!pip install -U keras"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qC1MlHPXhHX"
      },
      "source": [
        "# Import the tools we will need from keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLEBBwo4XhHY"
      },
      "source": [
        "# Initialize and fit the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5gzjZKUXhHY"
      },
      "source": [
        "# Use that tokenizer to transform the text messages in the training and test sets\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYnnJm1ZXhHY",
        "outputId": "3ada56ca-395c-4cc9-fb51-0b11c36c8712"
      },
      "source": [
        "# What do these sequences look like?\n",
        "X_train_seq[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[52,\n",
              " 8,\n",
              " 1,\n",
              " 324,\n",
              " 325,\n",
              " 22,\n",
              " 59,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 60,\n",
              " 611,\n",
              " 22,\n",
              " 59,\n",
              " 151,\n",
              " 77,\n",
              " 4,\n",
              " 326,\n",
              " 78,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXJ9ljoNXhHY"
      },
      "source": [
        "# Pad the sequences so each sequence is the same length\n",
        "X_train_seq_padded = pad_sequences(X_train_seq, 50)\n",
        "X_test_seq_padded = pad_sequences(X_test_seq, 50)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3GXzAAjXhHZ",
        "outputId": "a8ce8ef5-ea15-4fb2-f833-fa0f6e514e64"
      },
      "source": [
        "# What do these padded sequences look like?\n",
        "X_train_seq_padded[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,  52,   8,   1, 324, 325,  22,  59, 608, 609,\n",
              "       610,  60, 611,  22,  59, 151,  77,   4, 326,  78,   1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9FPu1iHXhHZ"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlN-ZEqCXhHZ"
      },
      "source": [
        "# Import the tools needed from keras and define functions to calculate recall and precision\n",
        "import keras.backend as K\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.models import Sequential\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WutZBsKmXhHZ",
        "outputId": "6de4f77e-0962-4ac7-e2d9-3fc495d1bca0"
      },
      "source": [
        "# Construct a simple RNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
        "model.add(LSTM(32, dropout=0, recurrent_dropout=0))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          56512     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 65,921\n",
            "Trainable params: 65,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izLFStm7XhHa"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision_m, recall_m])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo1R1HxpXhHa",
        "outputId": "33dbb7cd-514d-4071-ed8a-87d405dbe2e3"
      },
      "source": [
        "# Fit the RNN model\n",
        "history = model.fit(X_train_seq_padded, y_train, \n",
        "                    batch_size=32, epochs=15,\n",
        "                    validation_data=(X_test_seq_padded, y_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "8/8 [==============================] - 3s 113ms/step - loss: 0.6898 - accuracy: 0.5676 - precision_m: 0.9456 - recall_m: 0.5973 - val_loss: 0.6592 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6501 - accuracy: 0.9389 - precision_m: 0.9398 - recall_m: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5561 - accuracy: 0.9253 - precision_m: 0.9262 - recall_m: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3253 - accuracy: 0.9252 - precision_m: 0.9226 - recall_m: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.2228 - accuracy: 0.9424 - precision_m: 0.9424 - recall_m: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1933 - accuracy: 0.9519 - precision_m: 0.9527 - recall_m: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2232 - accuracy: 0.9412 - precision_m: 0.9395 - recall_m: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.2327 - accuracy: 0.9370 - precision_m: 0.9361 - recall_m: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2353 - accuracy: 0.9353 - precision_m: 0.9361 - recall_m: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2460 - accuracy: 0.9302 - precision_m: 0.9310 - recall_m: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.2088 - accuracy: 0.9441 - precision_m: 0.9433 - recall_m: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.1816 - accuracy: 0.9527 - precision_m: 0.9536 - recall_m: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1821 - accuracy: 0.9505 - precision_m: 0.9496 - recall_m: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2434 - accuracy: 0.9229 - precision_m: 0.9229 - recall_m: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.1416 - accuracy: 0.9599 - precision_m: 0.9573 - recall_m: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9667 - val_precision_m: 0.9688 - val_recall_m: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Mze5_wEhXhHb",
        "outputId": "849cdcd7-0526-4ca4-b020-0423223e58a8"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Loss')\n",
        "\n",
        "pyplot.plot(history.history['loss'])\n",
        "#pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}